{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3172 4142 4506 4279 4782 5048 5213 5106 5053 4750 4816 4769 4610 4805\n",
      " 4828 4861 4767 4624 4549 4463 4462 4446 4445 4336 4381 4319 4207 4305\n",
      " 4311 3991 4168 3942 4061 4362 4318 4252 4869 5284 5055 3591 5175 5217\n",
      " 5058 4969 4721 4291 4555 4886 4868 4806 4783 4811 4709 3903 3795 3715\n",
      " 2591 2130 2269 2480 3145 3626 4060 4296 4211 4225 4157 4133 4082 4048\n",
      " 3935 3843 3784 3642 3271 2707 1707 1564 1838 1719 2229 2764 2919 2873\n",
      " 2977 2913 3034 3051 3124 3101 3033 2713 2740 2947 2706 2834 2856 2683\n",
      " 2400 2229 1822 1542 1097 1029 1020 1026 1009 1011 1047 1069 1100 1122\n",
      " 1259 1365 1261 1374 1630 1851 2028 2130 2170 2205 2214 2204 2100 2106\n",
      " 2146 2089 2078 2134 2127 2074 2057 2045 2003 1999 1959 1924 1883 1843\n",
      " 1781 1716 1698 1645 1540 1410 1294 1131 1044 1029 1006 1017 1000  995\n",
      "  997 1003 1016 1001 1003 1002 1005 1004 1008 1032 1045 1100 1212 1295\n",
      " 1244 1100 1103 1216 1346 1330 1259 1251 1313 1372 1393 1402 1396 1381\n",
      " 1396 1381 1353 1346 1341 1332 1324 1310 1318 1330 1310 1292 1280 1275\n",
      " 1266 1264 1233 1241 1232 1215 1215 1187 1168 1171 1150 1134 1123 1135\n",
      " 1094 1090 1112 1090 1062 1069 1057 1020 1020 1005]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "dataset = io.loadmat('Indian_pines.mat')['indian_pines']\n",
    "gt_labels = io.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
    "print(dataset[0][0])\n",
    "print(gt_labels[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {x:[] for x in range(1,17)}\n",
    "(x,y,z) = dataset.shape\n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        l = gt_labels[i][j]\n",
    "        if l!=0:\n",
    "            a[l].append(np.array(dataset[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "1428\n",
      "830\n",
      "237\n",
      "483\n",
      "730\n",
      "28\n",
      "478\n",
      "20\n",
      "972\n",
      "2455\n",
      "593\n",
      "205\n",
      "1265\n",
      "386\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    print(len(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "count=0\n",
    "for i in range(1,17):\n",
    "    if(len(a[i])>480):\n",
    "        count+=1\n",
    "        for j in range(len(a[i])):\n",
    "            X.append(a[i][j])\n",
    "            y.append(count)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.utils import to_categorical\n",
    "X = normalize(X,axis=1,return_norm=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "X_test = X_test.reshape(len(X_test),220,1,1)\n",
    "X_train = X_train.reshape(len(X_train),220,1,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = y_train[:,1:]\n",
    "y_test = y_test[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , Flatten, MaxPooling2D , Dropout\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform\n",
    "def model_generator(n1,k1,k2,n4,n5,n_k,a1,a2,a3):\n",
    "    initializer = RandomUniform(minval=-0.05, maxval=0.05)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(n_k, kernel_size=(k1,1), activation=a1, input_shape=(n1,1,1),kernel_initializer=initializer,bias_initializer='zeros'))\n",
    "    model.add(MaxPooling2D(pool_size = (k2,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n4,activation=a2,kernel_initializer=initializer))\n",
    "    model.add(Dense(n5,activation = a3))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_generator(220,24,5,100,count,20,'tanh','tanh','softmax')\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7880 samples, validate on 876 samples\n",
      "Epoch 1/75\n",
      "7880/7880 [==============================] - 5s 692us/step - loss: 1.4348 - acc: 0.4487 - val_loss: 1.2962 - val_acc: 0.4795\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.47945, saving model to weights-improvement-01-0.48.hdf5\n",
      "Epoch 2/75\n",
      "7880/7880 [==============================] - 4s 529us/step - loss: 1.2648 - acc: 0.4963 - val_loss: 1.2368 - val_acc: 0.5114\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.47945 to 0.51142, saving model to weights-improvement-02-0.51.hdf5\n",
      "Epoch 3/75\n",
      "7880/7880 [==============================] - 4s 525us/step - loss: 1.2106 - acc: 0.5178 - val_loss: 1.2520 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51142\n",
      "Epoch 4/75\n",
      "7880/7880 [==============================] - 4s 483us/step - loss: 1.1434 - acc: 0.5487 - val_loss: 1.1542 - val_acc: 0.5445\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.51142 to 0.54452, saving model to weights-improvement-04-0.54.hdf5\n",
      "Epoch 5/75\n",
      "7880/7880 [==============================] - 4s 481us/step - loss: 1.0828 - acc: 0.5660 - val_loss: 1.0811 - val_acc: 0.5594\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.54452 to 0.55936, saving model to weights-improvement-05-0.56.hdf5\n",
      "Epoch 6/75\n",
      "7880/7880 [==============================] - 4s 489us/step - loss: 1.0339 - acc: 0.5906 - val_loss: 1.0194 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.55936 to 0.58333, saving model to weights-improvement-06-0.58.hdf5\n",
      "Epoch 7/75\n",
      "7880/7880 [==============================] - 4s 478us/step - loss: 0.9950 - acc: 0.6132 - val_loss: 0.9738 - val_acc: 0.6062\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.58333 to 0.60616, saving model to weights-improvement-07-0.61.hdf5\n",
      "Epoch 8/75\n",
      "7880/7880 [==============================] - 4s 502us/step - loss: 0.9472 - acc: 0.6345 - val_loss: 0.9852 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.60616 to 0.64612, saving model to weights-improvement-08-0.65.hdf5\n",
      "Epoch 9/75\n",
      "7880/7880 [==============================] - 4s 483us/step - loss: 0.8947 - acc: 0.6570 - val_loss: 0.8618 - val_acc: 0.6815\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.64612 to 0.68151, saving model to weights-improvement-09-0.68.hdf5\n",
      "Epoch 10/75\n",
      "7880/7880 [==============================] - 4s 486us/step - loss: 0.8609 - acc: 0.6703 - val_loss: 0.8202 - val_acc: 0.6781\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.68151\n",
      "Epoch 11/75\n",
      "7880/7880 [==============================] - 4s 486us/step - loss: 0.8190 - acc: 0.6912 - val_loss: 0.7935 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.68151 to 0.69521, saving model to weights-improvement-11-0.70.hdf5\n",
      "Epoch 12/75\n",
      "7880/7880 [==============================] - 4s 484us/step - loss: 0.7808 - acc: 0.7067 - val_loss: 0.7382 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.69521 to 0.72603, saving model to weights-improvement-12-0.73.hdf5\n",
      "Epoch 13/75\n",
      "7880/7880 [==============================] - 4s 509us/step - loss: 0.7593 - acc: 0.7135 - val_loss: 0.7094 - val_acc: 0.7557\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.72603 to 0.75571, saving model to weights-improvement-13-0.76.hdf5\n",
      "Epoch 14/75\n",
      "7880/7880 [==============================] - 4s 480us/step - loss: 0.7288 - acc: 0.7305 - val_loss: 0.7307 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75571\n",
      "Epoch 15/75\n",
      "7880/7880 [==============================] - 4s 469us/step - loss: 0.6995 - acc: 0.7383 - val_loss: 0.6990 - val_acc: 0.7454\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75571\n",
      "Epoch 16/75\n",
      "7880/7880 [==============================] - 4s 470us/step - loss: 0.6688 - acc: 0.7464 - val_loss: 0.6267 - val_acc: 0.7728\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.75571 to 0.77283, saving model to weights-improvement-16-0.77.hdf5\n",
      "Epoch 17/75\n",
      "7880/7880 [==============================] - 4s 501us/step - loss: 0.6664 - acc: 0.7453 - val_loss: 0.6369 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.77283 to 0.77397, saving model to weights-improvement-17-0.77.hdf5\n",
      "Epoch 18/75\n",
      "7880/7880 [==============================] - 4s 482us/step - loss: 0.6356 - acc: 0.7652 - val_loss: 0.6130 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77397\n",
      "Epoch 19/75\n",
      "7880/7880 [==============================] - 4s 519us/step - loss: 0.6144 - acc: 0.7704 - val_loss: 0.5814 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.77397 to 0.78425, saving model to weights-improvement-19-0.78.hdf5\n",
      "Epoch 20/75\n",
      "7880/7880 [==============================] - 4s 533us/step - loss: 0.6072 - acc: 0.7783 - val_loss: 0.5478 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.78425 to 0.80936, saving model to weights-improvement-20-0.81.hdf5\n",
      "Epoch 21/75\n",
      "7880/7880 [==============================] - 4s 548us/step - loss: 0.5809 - acc: 0.7801 - val_loss: 0.6098 - val_acc: 0.7705\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80936\n",
      "Epoch 22/75\n",
      "7880/7880 [==============================] - 4s 455us/step - loss: 0.5701 - acc: 0.7860 - val_loss: 0.7110 - val_acc: 0.7580\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80936\n",
      "Epoch 23/75\n",
      "7880/7880 [==============================] - 4s 518us/step - loss: 0.5539 - acc: 0.7957 - val_loss: 0.5460 - val_acc: 0.7888\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80936\n",
      "Epoch 24/75\n",
      "7880/7880 [==============================] - 4s 462us/step - loss: 0.5344 - acc: 0.8004 - val_loss: 0.6280 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80936\n",
      "Epoch 25/75\n",
      "7880/7880 [==============================] - 4s 450us/step - loss: 0.5327 - acc: 0.8005 - val_loss: 0.5096 - val_acc: 0.8002\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80936\n",
      "Epoch 26/75\n",
      "7880/7880 [==============================] - 4s 485us/step - loss: 0.5105 - acc: 0.8072 - val_loss: 0.4887 - val_acc: 0.8185\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.80936 to 0.81849, saving model to weights-improvement-26-0.82.hdf5\n",
      "Epoch 27/75\n",
      "7880/7880 [==============================] - 4s 466us/step - loss: 0.5039 - acc: 0.8076 - val_loss: 0.5094 - val_acc: 0.8002\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.81849\n",
      "Epoch 28/75\n",
      "7880/7880 [==============================] - 4s 459us/step - loss: 0.4959 - acc: 0.8123 - val_loss: 0.4643 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.81849 to 0.82420, saving model to weights-improvement-28-0.82.hdf5\n",
      "Epoch 29/75\n",
      "7880/7880 [==============================] - 4s 502us/step - loss: 0.4766 - acc: 0.8230 - val_loss: 0.4978 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82420\n",
      "Epoch 30/75\n",
      "7880/7880 [==============================] - 4s 485us/step - loss: 0.4736 - acc: 0.8195 - val_loss: 0.4341 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.82420 to 0.83105, saving model to weights-improvement-30-0.83.hdf5\n",
      "Epoch 31/75\n",
      "7880/7880 [==============================] - 4s 564us/step - loss: 0.4573 - acc: 0.8289 - val_loss: 0.4209 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.83105 to 0.84475, saving model to weights-improvement-31-0.84.hdf5\n",
      "Epoch 32/75\n",
      "7880/7880 [==============================] - 4s 445us/step - loss: 0.4573 - acc: 0.8269 - val_loss: 0.4042 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.84475 to 0.85731, saving model to weights-improvement-32-0.86.hdf5\n",
      "Epoch 33/75\n",
      "7880/7880 [==============================] - 4s 486us/step - loss: 0.4547 - acc: 0.8246 - val_loss: 0.4696 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.85731\n",
      "Epoch 34/75\n",
      "7880/7880 [==============================] - 4s 463us/step - loss: 0.4405 - acc: 0.8334 - val_loss: 0.4176 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.85731\n",
      "Epoch 35/75\n",
      "7880/7880 [==============================] - 4s 487us/step - loss: 0.4349 - acc: 0.8350 - val_loss: 0.4346 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.85731\n",
      "Epoch 36/75\n",
      "7880/7880 [==============================] - 4s 516us/step - loss: 0.4214 - acc: 0.8426 - val_loss: 0.5219 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.85731\n",
      "Epoch 37/75\n",
      "7880/7880 [==============================] - 4s 495us/step - loss: 0.4176 - acc: 0.8386 - val_loss: 0.4181 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.85731\n",
      "Epoch 38/75\n",
      "7880/7880 [==============================] - 4s 449us/step - loss: 0.4103 - acc: 0.8464 - val_loss: 0.4052 - val_acc: 0.8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_acc did not improve from 0.85731\n",
      "Epoch 39/75\n",
      "7880/7880 [==============================] - 4s 494us/step - loss: 0.4005 - acc: 0.8496 - val_loss: 0.3643 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.85731 to 0.86301, saving model to weights-improvement-39-0.86.hdf5\n",
      "Epoch 40/75\n",
      "7880/7880 [==============================] - 4s 483us/step - loss: 0.3898 - acc: 0.8577 - val_loss: 0.3543 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.86301 to 0.88014, saving model to weights-improvement-40-0.88.hdf5\n",
      "Epoch 41/75\n",
      "7880/7880 [==============================] - 4s 473us/step - loss: 0.3939 - acc: 0.8504 - val_loss: 0.4099 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.88014\n",
      "Epoch 42/75\n",
      "7880/7880 [==============================] - 4s 470us/step - loss: 0.3869 - acc: 0.8549 - val_loss: 0.3453 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.88014 to 0.88813, saving model to weights-improvement-42-0.89.hdf5\n",
      "Epoch 43/75\n",
      "7880/7880 [==============================] - 4s 446us/step - loss: 0.3825 - acc: 0.8584 - val_loss: 0.3664 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.88813\n",
      "Epoch 44/75\n",
      "7880/7880 [==============================] - 4s 509us/step - loss: 0.3744 - acc: 0.8637 - val_loss: 0.3858 - val_acc: 0.8562\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.88813\n",
      "Epoch 45/75\n",
      "7880/7880 [==============================] - 4s 495us/step - loss: 0.3761 - acc: 0.8610 - val_loss: 0.3763 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.88813\n",
      "Epoch 46/75\n",
      "7880/7880 [==============================] - 4s 489us/step - loss: 0.3660 - acc: 0.8636 - val_loss: 0.3986 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.88813\n",
      "Epoch 47/75\n",
      "7880/7880 [==============================] - 4s 535us/step - loss: 0.3590 - acc: 0.8671 - val_loss: 0.3645 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.88813\n",
      "Epoch 48/75\n",
      "7880/7880 [==============================] - 6s 752us/step - loss: 0.3545 - acc: 0.8687 - val_loss: 0.5295 - val_acc: 0.7968\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.88813\n",
      "Epoch 49/75\n",
      "7880/7880 [==============================] - 5s 596us/step - loss: 0.3527 - acc: 0.8687 - val_loss: 0.3337 - val_acc: 0.8824\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.88813\n",
      "Epoch 50/75\n",
      "7880/7880 [==============================] - 5s 590us/step - loss: 0.3491 - acc: 0.8679 - val_loss: 0.3976 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.88813\n",
      "Epoch 51/75\n",
      "7880/7880 [==============================] - 4s 518us/step - loss: 0.3460 - acc: 0.8713 - val_loss: 0.3249 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.88813\n",
      "Epoch 52/75\n",
      "7880/7880 [==============================] - 4s 526us/step - loss: 0.3491 - acc: 0.8721 - val_loss: 0.3702 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.88813\n",
      "Epoch 53/75\n",
      "7880/7880 [==============================] - 4s 555us/step - loss: 0.3360 - acc: 0.8777 - val_loss: 0.3057 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.88813 to 0.90639, saving model to weights-improvement-53-0.91.hdf5\n",
      "Epoch 54/75\n",
      "7880/7880 [==============================] - 5s 572us/step - loss: 0.3333 - acc: 0.8769 - val_loss: 0.3163 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.90639\n",
      "Epoch 55/75\n",
      "7880/7880 [==============================] - 5s 622us/step - loss: 0.3309 - acc: 0.8778 - val_loss: 0.3112 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.90639\n",
      "Epoch 56/75\n",
      "7880/7880 [==============================] - 4s 502us/step - loss: 0.3286 - acc: 0.8786 - val_loss: 0.3302 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.90639\n",
      "Epoch 57/75\n",
      "7880/7880 [==============================] - 4s 499us/step - loss: 0.3304 - acc: 0.8749 - val_loss: 0.3100 - val_acc: 0.8961\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.90639\n",
      "Epoch 58/75\n",
      "7880/7880 [==============================] - 4s 517us/step - loss: 0.3235 - acc: 0.8819 - val_loss: 0.3229 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.90639\n",
      "Epoch 59/75\n",
      "7880/7880 [==============================] - 4s 516us/step - loss: 0.3320 - acc: 0.8775 - val_loss: 0.3761 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.90639\n",
      "Epoch 60/75\n",
      "7880/7880 [==============================] - 4s 504us/step - loss: 0.3260 - acc: 0.8773 - val_loss: 0.4043 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.90639\n",
      "Epoch 61/75\n",
      "7880/7880 [==============================] - 4s 534us/step - loss: 0.3166 - acc: 0.8882 - val_loss: 0.3417 - val_acc: 0.8824\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.90639\n",
      "Epoch 62/75\n",
      "7880/7880 [==============================] - 4s 525us/step - loss: 0.3094 - acc: 0.8854 - val_loss: 0.3092 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.90639\n",
      "Epoch 63/75\n",
      "7880/7880 [==============================] - 4s 448us/step - loss: 0.3100 - acc: 0.8815 - val_loss: 0.2763 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.90639\n",
      "Epoch 64/75\n",
      "7880/7880 [==============================] - 3s 441us/step - loss: 0.3093 - acc: 0.8882 - val_loss: 0.3209 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.90639\n",
      "Epoch 65/75\n",
      "7880/7880 [==============================] - 3s 444us/step - loss: 0.3079 - acc: 0.8840 - val_loss: 0.2864 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.90639\n",
      "Epoch 66/75\n",
      "7880/7880 [==============================] - 4s 451us/step - loss: 0.3084 - acc: 0.8852 - val_loss: 0.2960 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.90639 to 0.90753, saving model to weights-improvement-66-0.91.hdf5\n",
      "Epoch 67/75\n",
      "7880/7880 [==============================] - 4s 444us/step - loss: 0.2931 - acc: 0.8934 - val_loss: 0.3234 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.90753\n",
      "Epoch 68/75\n",
      "7880/7880 [==============================] - 3s 439us/step - loss: 0.2929 - acc: 0.8930 - val_loss: 0.3955 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.90753\n",
      "Epoch 69/75\n",
      "7880/7880 [==============================] - 3s 442us/step - loss: 0.2952 - acc: 0.8916 - val_loss: 0.2812 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.90753\n",
      "Epoch 70/75\n",
      "7880/7880 [==============================] - 4s 499us/step - loss: 0.2966 - acc: 0.8909 - val_loss: 0.2752 - val_acc: 0.9041\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.90753\n",
      "Epoch 71/75\n",
      "7880/7880 [==============================] - 4s 488us/step - loss: 0.2867 - acc: 0.8961 - val_loss: 0.2618 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.90753 to 0.91895, saving model to weights-improvement-71-0.92.hdf5\n",
      "Epoch 72/75\n",
      "7880/7880 [==============================] - 4s 472us/step - loss: 0.2901 - acc: 0.8940 - val_loss: 0.3274 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.91895\n",
      "Epoch 73/75\n",
      "7880/7880 [==============================] - 4s 464us/step - loss: 0.2829 - acc: 0.8980 - val_loss: 0.2634 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.91895\n",
      "Epoch 74/75\n",
      "7880/7880 [==============================] - 4s 484us/step - loss: 0.2873 - acc: 0.8915 - val_loss: 0.3114 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.91895\n",
      "Epoch 75/75\n",
      "7880/7880 [==============================] - 4s 526us/step - loss: 0.2815 - acc: 0.8972 - val_loss: 0.3272 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.91895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda95ebc400>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs = 75,verbose=1,batch_size=8,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
